{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import os\n",
    "# for i in range(12,1200):\n",
    "#     fname = os.path.join('New_Dataset',str(i)+'.csv')\n",
    "#     with open(fname,'w',newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow([\"Image\",\"Annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_on_csv(idx,Image,GTname):\n",
    "    for i in idx:\n",
    "        fname = os.path.join('New_Dataset',str(i)+'.csv')\n",
    "        with open(fname,'a+',newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([Image,GTname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = [\"color\",\"object\",\"part\",\"material\",\"scene\",\"texture\"]\n",
    "\n",
    "class conceptLoader(Dataset):\n",
    "    \"\"\"Broaden Dataset Image Loader\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            conceptType (string): type of the concept to load.\n",
    "        \"\"\"\n",
    "        self.c_flag = False  # Concept Flag\n",
    "        csv_file = os.path.join(root_dir,\"index.csv\") \n",
    "        root_dir = os.path.join(root_dir,\"images\") \n",
    "        self.fileNames = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fileNames)\n",
    "    \n",
    "\n",
    "    def load_concept(self,idx,conceptType):\n",
    "        c_index = str(self.fileNames.iloc[idx, concepts.index(conceptType)+6])\n",
    "        image_name = str(self.fileNames.iloc[idx, 0])\n",
    "        if c_index=='nan':\n",
    "            self.c_flag = False\n",
    "            # sample = torch.zeros([1, 113, 113])\n",
    "            sample =0\n",
    "        else:\n",
    "            self.c_flag = True\n",
    "            if conceptType ==\"scene\" or conceptType ==\"texture\":\n",
    "                sample  = c_index.split(\";\") \n",
    "            elif conceptType ==\"part\":\n",
    "                items  = c_index.split(\";\") \n",
    "                sample = []\n",
    "                c_index=[]\n",
    "                for i in items:\n",
    "                    img_name = os.path.join(self.root_dir,i)\n",
    "                    image = Image.open(img_name)\n",
    "                    px = np.array(image)\n",
    "                    item = self.decodeClassMask(px)\n",
    "                    sample.append(item)\n",
    "                    c_index.append(i)\n",
    "                \n",
    "            else:\n",
    "                img_name = os.path.join(self.root_dir,c_index)\n",
    "                image = Image.open(img_name)\n",
    "                px = np.array(image)\n",
    "                sample = self.decodeClassMask(px)\n",
    "                #sample = Image.fromarray(sample)\n",
    "                #sample = TF.to_tensor(sample)     \n",
    "\n",
    "        # sample.unsqueeze_(0)\n",
    "        return self.c_flag, sample,image_name,c_index\n",
    "\n",
    "    def decodeClassMask(self,im):\n",
    "        ''' Decodes pixel-level object/part class and instance data from\n",
    "        the given image, previously encoded into RGB channels.'''\n",
    "    # Classes are a combination of RG channels\n",
    "        return (im[:,:,0] + (im[:,:,1])*256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "    dataset_path='./broden1_227'\n",
    "    # data_obj = imageLoader(dataset_path)\n",
    "    data_obj = conceptLoader(dataset_path)\n",
    "    for j in range(63305):\n",
    "        flag,aa,ImgName, ConName = data_obj.load_concept(j,\"material\")\n",
    "        print(j)\n",
    "        if flag:\n",
    "            k=np.unique(aa)\n",
    "            add_on_csv(k,ImgName,ConName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "    dataset_path='./broden1_227'\n",
    "    # data_obj = imageLoader(dataset_path)\n",
    "    data_obj = conceptLoader(dataset_path)\n",
    "    for j in range(63305):\n",
    "        flag,aa,ImgName, ConName = data_obj.load_concept(j,\"part\")\n",
    "\n",
    "        if flag:\n",
    "            for i in range(len(aa)):\n",
    "                k=np.unique(aa[i])\n",
    "                add_on_csv(k,ImgName,ConName[i])\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 1.]\n [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "aa=np.zeros((2,2))\n",
    "aa[0,0]=1\n",
    "aa[aa!=1]=0\n",
    "\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "x=torch.ones([10,3,155,155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.ones([x.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()  \n",
    "dir = os.path.join(cwd,\"Tk\")\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}